{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02a2849c-5163-4651-a22f-d7174a5253a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/am44/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/am44/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import networkx as nx\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and tokenize sentences\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)  # Split into sentences\n",
    "    tokenized_sentences = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent.lower())  # Convert to lowercase and tokenize\n",
    "        words = [word for word in words if word.isalnum() and word not in stop_words]  # Remove punctuation and stopwords\n",
    "        tokenized_sentences.append(words)\n",
    "    \n",
    "    return sentences, tokenized_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82d333fc-5fd1-404d-86e4-1b770a4d10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def build_similarity_matrix(sentences):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # Compute cosine similarity between all sentences\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    \n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29173f93-9d0f-4c26-937a-5851bc9d1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_summarize(text, num_sentences=3):\n",
    "    sentences, tokenized_sentences = preprocess_text(text)\n",
    "    \n",
    "    if len(sentences) < num_sentences:\n",
    "        return \" \".join(sentences)  # Return full text if too short\n",
    "\n",
    "    similarity_matrix = build_similarity_matrix([\" \".join(words) for words in tokenized_sentences])\n",
    "    \n",
    "    # Build a graph and apply PageRank\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    # Rank sentences based on PageRank scores\n",
    "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    \n",
    "    # Extract the top N sentences\n",
    "    summary = \" \".join([ranked_sentences[i][1] for i in range(num_sentences)])\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffbd18ae-3049-4ac3-8c18-9cfed74398b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization completed. Check summarized_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('prepared_data.csv')\n",
    "\n",
    "# Apply summarization to each row\n",
    "df['summary'] = df['content'].apply(lambda x: textrank_summarize(str(x), num_sentences=3))\n",
    "\n",
    "# Save results\n",
    "df.to_csv('summarized_data.csv', index=False)\n",
    "\n",
    "print(\"Summarization completed. Check summarized_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07346f7e-bfe4-41ed-a893-614947f41f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>1. Introduction of Word2vec\\n\\nWord2vec is one...</td>\n",
       "      <td>At first, we need to generate a format of ‘lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>In my last article, I introduced the concept o...</td>\n",
       "      <td>In this blog post, we will be using PyTorch an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>Introduction\\n\\nThanks to its strict implement...</td>\n",
       "      <td>The Grammar of Graphics\\n\\nIn case you should ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Data Frames as CSV Fil...</td>\n",
       "      <td>Photo credit to Mika Baumeister from Unsplash\\...</td>\n",
       "      <td>DBFS FileStore is where you create folders and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>Let’s derive the formula for calculating gradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192387</th>\n",
       "      <td>Why do you need a cleaning service?</td>\n",
       "      <td>What could be more important than having a tid...</td>\n",
       "      <td>So, whether you live in Sydney or North Shore,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192388</th>\n",
       "      <td>Daily cleaning and maintenance of bedding</td>\n",
       "      <td>Daily cleaning and maintenance of bedding\\n\\nW...</td>\n",
       "      <td>General the washing temperature is not exceed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192389</th>\n",
       "      <td>Beneficial Advice on Bond Cleaning!</td>\n",
       "      <td>The most important chore at the end is bond cl...</td>\n",
       "      <td>The most important chore at the end is bond cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192390</th>\n",
       "      <td>How I Learned Romanian in 37 Easy Steps</td>\n",
       "      <td>How I Learned Romanian in 37 Easy Steps\\n\\nHey...</td>\n",
       "      <td>Step 3 — Go to Romania, meet 5,012 people who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192391</th>\n",
       "      <td>Trying Pimsleur Cantonese in Hong Kong</td>\n",
       "      <td>Over the past few years, I’ve heard a number o...</td>\n",
       "      <td>Back when I first started studying Chinese in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0       A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1       Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                            How to Use ggplot2 in Python   \n",
       "3       Databricks: How to Save Data Frames as CSV Fil...   \n",
       "4       A Step-by-Step Implementation of Gradient Desc...   \n",
       "...                                                   ...   \n",
       "192387                Why do you need a cleaning service?   \n",
       "192388          Daily cleaning and maintenance of bedding   \n",
       "192389                Beneficial Advice on Bond Cleaning!   \n",
       "192390            How I Learned Romanian in 37 Easy Steps   \n",
       "192391             Trying Pimsleur Cantonese in Hong Kong   \n",
       "\n",
       "                                                  content  \\\n",
       "0       1. Introduction of Word2vec\\n\\nWord2vec is one...   \n",
       "1       In my last article, I introduced the concept o...   \n",
       "2       Introduction\\n\\nThanks to its strict implement...   \n",
       "3       Photo credit to Mika Baumeister from Unsplash\\...   \n",
       "4       A Step-by-Step Implementation of Gradient Desc...   \n",
       "...                                                   ...   \n",
       "192387  What could be more important than having a tid...   \n",
       "192388  Daily cleaning and maintenance of bedding\\n\\nW...   \n",
       "192389  The most important chore at the end is bond cl...   \n",
       "192390  How I Learned Romanian in 37 Easy Steps\\n\\nHey...   \n",
       "192391  Over the past few years, I’ve heard a number o...   \n",
       "\n",
       "                                                  summary  \n",
       "0       At first, we need to generate a format of ‘lis...  \n",
       "1       In this blog post, we will be using PyTorch an...  \n",
       "2       The Grammar of Graphics\\n\\nIn case you should ...  \n",
       "3       DBFS FileStore is where you create folders and...  \n",
       "4       Let’s derive the formula for calculating gradi...  \n",
       "...                                                   ...  \n",
       "192387  So, whether you live in Sydney or North Shore,...  \n",
       "192388  General the washing temperature is not exceed ...  \n",
       "192389  The most important chore at the end is bond cl...  \n",
       "192390  Step 3 — Go to Romania, meet 5,012 people who ...  \n",
       "192391  Back when I first started studying Chinese in ...  \n",
       "\n",
       "[192392 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('summarized_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b77962a-5e4e-4f94-bd51-6b8cdff77409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my last article, I introduced the concept of Graph Neural Network (GNN) and some recent advancements of it. Since this topic is getting seriously hyped up, I decided to make this tutorial on how to easily implement your Graph Neural Network in your project. You will learn how to construct your own GNN with PyTorch Geometric, and how to use GNN to solve a real-world problem (Recsys Challenge 2015).\n",
      "\n",
      "In this blog post, we will be using PyTorch and PyTorch Geometric (PyG), a Graph Neural Network framework built on top of PyTorch that runs blazingly fast. It is several times faster than the most well-known GNN framework, DGL.\n",
      "\n",
      "Aside from its remarkable speed, PyG comes with a collection of well-implemented GNN models illustrated in various papers. Therefore, it would be very handy to reproduce the experiments with PyG.\n"
     ]
    }
   ],
   "source": [
    "print(df['content'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21465045-7741-47bd-8eb1-5cad10bb798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this blog post, we will be using PyTorch and PyTorch Geometric (PyG), a Graph Neural Network framework built on top of PyTorch that runs blazingly fast. In my last article, I introduced the concept of Graph Neural Network (GNN) and some recent advancements of it. You will learn how to construct your own GNN with PyTorch Geometric, and how to use GNN to solve a real-world problem (Recsys Challenge 2015).\n"
     ]
    }
   ],
   "source": [
    "print(df['summary'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4ee3e85-915d-4583-a5a7-e57876a09a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I Learned from (Two-time) Kaggle Grandmaster Abhishek Thakur\n",
      "\n",
      "Photo by Georgie Cobbs on Unsplash\n",
      "\n",
      "Quick Bio\n",
      "\n",
      "Before his many data scientist stints in companies scattered throughout Germany, Abhishek Thakur earned his bachelor’s in electrical engineering at NIT Surat and his master’s in computer science at the University of Bonn. Currently, he holds the title of Chief Data Scientist at Norway’s boost.ai, a “software company that specializes in conversational artificial intelligence (AI).” But I’m most impressed by Abhishek’s Kaggle clout.\n",
      "\n",
      "You can visit his Kaggle profile here. Here’s a snapshot of his accolades:\n",
      "\n",
      "Competitions Grandmaster (17 gold medals and an all-time high rank of #3 in the world)\n",
      "\n",
      "Kernels Expert (he’s well within the top 1% of Kagglers)\n",
      "\n",
      "Discussion Grandmaster (65 gold medals and an all-time high rank of #2 in the world)\n",
      "\n",
      "I want to take a look at Abhishek’s tutorial, Approaching (Almost) Any NLP Problem on Kaggle. I’ve selected this kernel of Abhishek’s because I myself have been trying to learn more about natural language processing, and how could I resist learning with Kaggle’s Halloween-themed Spooky Authors dataset?\n",
      "\n",
      "Abhishek’s Approach to NLP\n",
      "\n",
      "I would highly encourage you to read this article alongside the kernel. And if you really want a firmer grasp of NLP or data science in general, be sure that you understand every line of Abhishek’s code by writing it yourself as you go through his kernel.\n",
      "\n",
      "Just so we don’t forget — our task is to identify the author (EAP — Edgar Allen Poe; HPL — H.P. Lovecraft; MWS — Mary Wollstonecraft Shelley) of each sentence in the test set.\n",
      "\n",
      "1. Exploring the Data and Understanding the Problem\n",
      "\n",
      "After importing the necessary Python modules and the data, Abhishek calls the head() method on the data to see what the first five rows look like. Since Abhishek is a pro and this is an NLP problem, the exploratory data analysis (you’ll most often see this referred to as EDA) is shallow compared to problems involving numerical data. Data science newcomers might benefit from more thorough EDA. A…\n"
     ]
    }
   ],
   "source": [
    "print(df['content'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ace145a-4ad9-4cb9-8fb9-cb155ea79013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since Abhishek is a pro and this is an NLP problem, the exploratory data analysis (you’ll most often see this referred to as EDA) is shallow compared to problems involving numerical data. And if you really want a firmer grasp of NLP or data science in general, be sure that you understand every line of Abhishek’s code by writing it yourself as you go through his kernel. Exploring the Data and Understanding the Problem\n",
      "\n",
      "After importing the necessary Python modules and the data, Abhishek calls the head() method on the data to see what the first five rows look like.\n"
     ]
    }
   ],
   "source": [
    "print(df['summary'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f84332-d9a8-4920-b11f-07ad5fbe0c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "ROUGE-1: 0.2912\n",
      "ROUGE-2: 0.2827\n",
      "ROUGE-L: 0.2438\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import networkx as nx\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "df = pd.read_csv('summarized_data.csv')\n",
    "\n",
    "# Add these imports at the top\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Add this function to your code\n",
    "def evaluate_with_rouge(references, summaries):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "    \n",
    "    for ref, summ in zip(references, summaries):\n",
    "        scores = scorer.score(ref, summ)\n",
    "        rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "        rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "        rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "    return {\n",
    "        'rouge1': np.mean(rouge1_scores),\n",
    "        'rouge2': np.mean(rouge2_scores),\n",
    "        'rougeL': np.mean(rougeL_scores)\n",
    "    }\n",
    "\n",
    "# After generating summaries, evaluate them\n",
    "references = df['content'].apply(str).tolist()\n",
    "summaries = df['summary'].tolist()\n",
    "\n",
    "rouge_scores = evaluate_with_rouge(references, summaries)\n",
    "print(\"ROUGE Scores:\")\n",
    "print(f\"ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {rouge_scores['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {rouge_scores['rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b211f-35f1-42a9-ac12-c0f9349d901f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
